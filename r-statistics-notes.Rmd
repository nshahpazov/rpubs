---
title: "Статистика с R"
date: "4/17/2021"
output:
  html_document:
    toc: true
    toc_depth: 2
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Точкови оценки
Ако имаме наблюдения $x_1, ..., x_n$ над случайна величина $X \sim \mathcal{N}(\mu, \sigma^2)$, 
то можем да мислим на всяко наблюдение $x_i$ като на наблюдение от случайна
величина $X_i$ разпределена като $X$ и $X_i$ са независими. Тоест, имаме
независими и еднакво разпределени (н.е.р.) случайни величини 
$X_1, ..., X_n \overset{distr}{\sim} X \sim \mathcal{N}(\mu, \sigma^2)$, като сме получили 
по едно наблюдение от всяка. Векторът $(X_1,...,X_n)$ наричаме **случайна извадка**.

Тогава $\bar{x} := \frac{1}{n}\sum_{i=1}^n{x_i}$ е наблюдение от
случайната величина $\bar{X} := \frac{1}{n}\sum_{i=1}^n{X_i} \sim \mathcal{N}(\mu, \frac{\sigma^2}{n})$,
понеже 
$$
E[\bar{X}] = E[\frac{1}{n}\sum_{i=1}^n{X_i}]=\frac{1}{n}\sum_{i=1}^n{E[X_i]}=\frac{1}{n}n\mu = \mu\\
Var[\bar{X}]=Var[\frac{1}{n}\sum_{i=1}^n{X_i}] = \frac{1}{n^2}n\sigma^2=\frac{\sigma^2}{n}
$$

Забелязваме, че $Var[\bar{X}] \xrightarrow[n\to \infty]{} 0$.
Тоест, колкото повече наблюдения имаме, толкова повече $\bar{x}$ има вероятност да е близо 
до истинския параметър $\mu$,
понеже ще е наблюдение от нормално разпределена случайна величина с дисперсия
$\frac{\sigma^2}{n}$ и очакване $\mu$.

Можем да наблюдаваме този факт със следната симулация

```{r libs, include=FALSE, results="hide"}
library("tidyverse")
library("ggplot2")
library("ggridges")
library(UsingR)
```

```{r simulation-of-mean, fig.height = 4, fig.width = 7}
# library("tidyverse")
# library("ggplot2")

# брой извадки които взимаме
n <- 1000

# 1000 пъти взимаме средно на 10, 100 и 1000 наблюдения от N(25, 40^2)
c(10, 100, 1000) %>%
  map(function(size) {
    # Взимаме средното на size на брой наблюдения от N(25, 40^2)
    map(1:n, ~mean(rnorm(size, mean = 25, sd = 40))) %>%
      unlist() %>%
      data.frame(x = ., size = as.character(size))
  }) %>%
  bind_rows() %>%
  ggplot() +
  geom_density(mapping = aes(x = x, fill = size)) +
  facet_wrap(~size) +
  ggtitle("Емпирично Разпределение на извадково средно при n=10, 100, 1000") +
  xlab("извадково средно") +
  ylab("емпирична плътност на извадково средно")
```

Още една визуализация

```{r simulation-of-mean-2, echo=TRUE}
# library("ggridges")

c(10, 50, 100, 250, 500, 750, 1000, 1500, 2000, 5000) %>%
  map(function(size) {
    # Симулираме 1000 на брой извадкови средни от #size наблюдения
    map(1:1000, ~mean(rnorm(size, mean = 25, sd = 40))) %>%
      unlist() %>%
      data.frame(x = ., size = as.factor(size))
  }) %>%
  bind_rows() %>%
  ggplot(mapping = aes(x = x, y = size, fill = size, group = size)) +
  geom_density_ridges2(
    scale = 2, alpha = 0.6, rel_min_height = 0.01,
    # jittered_points = TRUE, position = "raincloud"
  ) +
  ggtitle("Емпирично Разпределение на извадково средно") +
  xlab("извадково средно") +
  ylab("емпирична плътност на извадково средно")
```

$\bar{X}$ наричаме **точкова оценка** за параметъра $\mu$.
Това, че $Е(\bar{X}) = \mu$ наричаме **неизместеност** на оценката.
Когато една точкова оценка $f_{\theta}(\overrightarrow{X})$ приближава по вероятност своя параметър $\theta$,
тоест 
$$
\lim_{n\to \infty}Pr(|f_{\theta}(\overrightarrow{X}) - \theta| > \epsilon) = 0 \text{ за } \forall \epsilon > 0
$$
казваме, че точковата оценка $f_{\theta}(\overrightarrow{X})$ е **асимптотично консистента**.

## Интервални Оценки

Ако имаме наблюдения над случайна величина $X \sim \mathcal{N}(\mu^?, \sigma^2)$ за която
$\mu^?$ е неизвестен параметър, но $\sigma^2$ е известна (в практиката рядко ще знаем който и да е параметър), то знаем, че 
$$
Z := \frac{\bar{X} - \mu^?}{\sigma/\sqrt{n}} \sim \mathcal{N}(0, 1)
$$
и следователно, можем да използваме определен квантил **q** от N(0, 1), така че
$$
P(-q < \frac{\bar{X} - \mu^?}{\sigma/\sqrt{n}} < q) = \gamma
$$

Така, с вероятност $\gamma$ (**ниво на достоверност**) можем да сме сигурни, че 
$$
\bar{X} - q  \frac{\sigma}{\sqrt{n}} < \mu^? < \bar{X} + q \frac{\sigma}{\sqrt{n}}
$$
В **R** за 95% интервал на достоверност, това ще стане по следния начин
```{r}
n <- 1000
known_sd <- 10 # сигма ни е известно, но мю не ни е и се опитваме да го оценим
x <- rnorm(n, 14.55, known_sd)

emp_mean <- mean(x)
q <- qnorm(0.975)

c(emp_mean - q * known_sd / sqrt(n), emp_mean + q * known_sd / sqrt(n))
```

В повечето случаи обаче, $\sigma$ не ни е известно. Тогава, ако заместим с извадковото 
стандартно отклонение **S**, случайната величина $\frac{\bar{X} - \mu}{S/\sqrt{n}}$ има 
$\mathcal{T}$ разпределение с $n - 1$ степени на свобода. В този случай, трябва просто да използваме 
квантилите от $\mathcal{T}$ разпределение.

```{r}
n <- 1000
x <- rnorm(n, 25, 7.654)

emp_mean <- mean(x)
emp_sd <- sd(x)

q <- qt(0.975, df = n - 1)

c(emp_mean - q * emp_sd / sqrt(n), emp_mean + q * emp_sd / sqrt(n))
```

Или с **t.test** функцията
```{r}
t.test(x)
```

Получената оценка за $\mu$ се нарича **интервална оценка**.
Ето как изглеждат интервалите на достоверност при Нормално и $\mathcal{T}$ разпределение за
случайната величина Z дефиниране по-горе. 
```{r confidence-interval}
# library("ggridge")

n <- 100000

list("normal" = rnorm(n), "t" = rt(n, 100000 - 1)) %>%
  imap(~data.frame(x = .x, distribution = .y)) %>%
  bind_rows() %>%
  ggplot(aes(x = x, y = distribution, fill = factor(stat(quantile)))) +
  stat_density_ridges(
    geom = "density_ridges_gradient",
    calc_ecdf = TRUE,
    quantiles = c(0.025, 0.975)
  ) +
  scale_fill_manual(
    name = "Probability", values = c("#FF0000A0", "#62b5b2", "#FF0000A0"),
    labels = c("(0, 0.025]", "(0.025, 0.975]", "(0.975, 1]")
  ) +
  xlab("Z") +
  theme_minimal()
```

## Тестване на хипотези върху една извадка

**Хипотеза** наричаме какво да е твърдение за функцията на разпределение $F_X$ на 
случайната величина $Х$ върху която имаме извадка $(X_1, ..., X_n)$.

Нека наблюдаваме данни идващи от нормално разпределение, примерно от $\mathcal{N}(176, 6)$
за които не знаем истинската стойност на $\mu$ (забравяме, че сме ги генерирали с $\mu=176$)

```{r}
heights <- rnorm(100, 176, 6)
```

Случва се така, че някой ни казва, че истинското средно е $\mu \ge 190$ (примерно ни лъже).
Ако примем, че истинското $\mu$ наистина $\ge$ 190, то случайната величина

$$
Z := \frac{\bar{X} - 190}{\sigma / \sqrt{n}}
$$
ще бъде нормално разпределена с $\mu=0$ и $\sigma^2=1$

```{r}
z <- (mean(heights) - 190) / (6 / sqrt(100))
z
```
Можем да видим вероятността да имаме стойност z или по-малка използвайки функцията **pnorm**

```{r}
pvalue <- pnorm(z)
pvalue
```
Виждаме, че ако хипотезата, че $\mu \ge 190$ e вярна, то е изключително малко вероятно да наблюдаваме данните които имаме. Тогава, можем да отхвърлим хипотезата, че $\mu \ge 190$. Но колко трябва да е
малко нашето **pvalue**, така че да отхвърлим хипотезета $H_0$ че $\mu \ge 190$ и да приемем алтернативата $H_1$ че $\mu < 190$. Ако изберем някакво $\alpha$, примерно $\alpha = 0.05$ (**ниво на значимост**) можем да отхвърляме 
хипотезата $H_0$ само когато $pvalue < \alpha := 0.05$ и вероятността $P(Отхвърляне|H_0=True):= \alpha$ да отхвърлим хипотезата $H_0$, когато тя е вярна е 0.05 (**Грешка от първи род**). Областта в която отхвърляме нулевата хипотеза $H_0$ наричаме 
**критична област**. Ако не успеем да отхвърлим хипотезата $H_0$ а тя се окаже грешна, правиме
**грешка от втори род**. Нейната вероятност $P(Приемане|H_0=False)$ бележим с $\beta$.

Когато $\sigma$ също е неизвестна, то
$$
Z := \frac{\bar{X} - 190}{S / \sqrt{n}} \sim \mathcal{T}(n-1)
$$
и за да видим вероятността да наблюдаваме такава стойност (или по-крайна), трябва да 
използваме функцията **pt** и да заместим $\sigma$ с $S$ във формулата за $Z$

```{r}
z <- (mean(heights) - 190) / (sd(heights) / sqrt(100))
pt(z, length(heights) - 1)
```

Отново, можем да използваме функцията **t.test**, която да ни даде цялата информация.

```{r}
t.test(heights, mu = 190, alternative = "less")
```

За разлика от подхода при интервални оценки, при тестване на хипотези, центрираме
**тестовата статистика** $Z$ около **хипотетичен параметър** и отхвърляме нулевата хипотеза
$H_0$ когато наблюдаваната (или по крайна) **тест статистика** $Z$ се случва с много малък шанс.

* Когато тестваме $H_0:= \mu \ge \mu_{хипотеза}$ срещу $H_1 := \mu < \mu_{хипотеза}$ правим 
**едностранен тест с лява опашка**. В този случай $pvalue := P(Z \le z |H_0)$, където $z$ е стойността 
която сме наблюдавали за тестовата статистика $Z$.

```{r echo=FALSE}
n <- 100000
list("normal" = rnorm(n), "t" = rt(n, 100000 - 1)) %>%
  imap(~data.frame(x = .x, distribution = .y)) %>%
  bind_rows() %>%
  ggplot(aes(x = x, y = distribution, fill = factor(stat(quantile)))) +
  stat_density_ridges(
    geom = "density_ridges_gradient",
    calc_ecdf = TRUE,
    quantiles = c(0.05)
  ) +
  scale_fill_manual(
    name = "Probability", values = c("#FF0000A0", "#62b5b2"),
    labels = c("(0, 0.05]", "(0.5, 1]")
  ) +
  xlab("Z") +
  theme_minimal()
```

* Когато тестваме $H_0:= \mu \le \mu_{хипотеза}$ срещу $H_1 := \mu > \mu_{хипотеза}$ правим 
**едностранен тест с дясна опашка**. В този случай $pvalue := P(Z \ge z |H_0)$, където $z$ е стойността 
която сме наблюдавали за тестовата статистика $Z$.

```{r}
# Тестване на хипотезата, че E(X) < 130
t.test(heights, mu = 130, alternative = "greater")
```

```{r echo=FALSE}
n <- 100000
list("normal" = rnorm(n), "t" = rt(n, 100000 - 1)) %>%
  imap(~data.frame(x = .x, distribution = .y)) %>%
  bind_rows() %>%
  ggplot(aes(x = x, y = distribution, fill = factor(stat(quantile)))) +
  stat_density_ridges(
    geom = "density_ridges_gradient",
    calc_ecdf = TRUE,
    quantiles = c(0.95)
  ) +
  scale_fill_manual(
    name = "Probability", values = c("#62b5b2", "#FF0000A0"),
    labels = c("(0, 0.95]", "(0.95, 1]")
  ) +
  xlab("Z") +
  theme_minimal()
```

* Когато тестваме $H_0:= \mu = \mu_{хипотеза}$ срещу $H_1 := \mu \neq \mu_{хипотеза}$ правим 
**двустранен тест с две опашки**. В този случай ще трябва да разделим **нивото на значимост** \alpha
на две за двете опашки така, че да правим грешка от първи род с $\alpha$ вероятност.
При тест с две опашки, дефинираме $pvalue := 2\min(P(Z \ge z|H_0), P(Z \le z|H_0))$.
Aко разпределението е симетрично около нулата, $pvalue := P(abs(Z) \ge abs(z) |H_0)$, 
където отново, $z$ е стойността която сме наблюдавали за тестовата статистика $Z$.

```{r}
# Тестване на хипотезата, че E(X) = 165
t.test(heights, mu = 130, alternative = "two.sided")
```

```{r confidence-interval, eval=TRUE, echo=FALSE}
```

Ако не искаме да правим грешка от първи род, можем да намалим областта на $\alpha$, но 
така ще отхвърляме прекалено лесно и ще качим вероятността за грешка от втори род.

## Тестване на хипотези върху две извадки
Ако имаме еднакъв брой наблюдения от две случайни величини $X$ и $Y$, които са нормално разпределени
 с еднакви дисперсии - съответно,
$X \sim \mathcal{N}(\mu_1, \sigma^2)$ и  $Y \sim \mathcal{N}(\mu_2, \sigma^2)$, можем да зададем 
нулева хипотеза $H_0 := \mu_1 = \mu_2$. Ако нулевата хипотеза е вярна, то
$\bar{X} - \bar{Y} \sim \mathcal{N}(0, \frac{\sigma^2}{n}  + \frac{\sigma^2}{m})$. Тогава

$$
Т := \frac{\bar{X}-\bar{Y}}{\sqrt{\frac{S_1^2}{n}  + \frac{S_2^2}{n}}} \sim \mathcal{T}(2n - 2)
$$
Тогава, можем да използваме досегашния подход при тестване на хипотези за да проверим дали наистина $\mu_1=\mu_2$.

Aко имаме $pvalue := P(abs(T) \ge abs(t)) < \alpha$, където $\alpha$ е **нивото на значимост**, а $t$ e наблюдаваната стойност за **T-статистиката**, можем да отхвърлим нулевата хипотеза, че $\mu_1=\mu_2$.

##### Пример:
```{r}
# брой елементи в двете случайни извадки
n <- 40
m <- 40

# Симулации на случайни извадки от с.в. X ~ N(3, 9) и Y ~ N(4, 9)
x <- rnorm(n, 3, 3)
y <- rnorm(m, 4, 3)

# Извадкови вариации
v1 <- var(x)
v2 <- var(y)

# Степени на свобода за T-разпределението
degrees_of_freedom <- n + m - 2

# Наблюдаваната стойност от T-статистиката
t <- (mean(x) - mean(y)) / sqrt(v1 / 40 + v2 / 40)

# Изчисление за pvalue при двустранен тест
pval <- 2 * min(
  pt(t, degrees_of_freedom),
  pt(t, degrees_of_freedom, lower.tail = FALSE)
)

# резултат
c("t" = t, "pvalue" = pval, "df" = degrees_of_freedom)
```

Или ако просто използваме **t.test**

```{r}
t.test(x, y, var.equal = TRUE)
```

---

Когато работим с предположението, че дисперсиите са еднакви, но имаме различен брой наблюдения от двете случайни извадки, за да оценим по-точно общата дисперсия посредством извадъчните дисперсии, използваме формулата за **комбинирана извадъчна дисперсия** и 
съответно - фoрмулата за **комбинирано стандартно отклонение**.

$$
S_p^2 = \frac{(n - 1)S_1^2 + (m - 1)S_2^2}{n + m - 2}
$$

където $n$ и $m$ са броят на елементите в двете извадки, а $S_i$ са извадъчните 
дисперсии на двете извадки. В този случай T-статистиката е 

$$
Т := \frac{\bar{X}-\bar{Y}}{S_p\sqrt{\frac{1}{n}  + \frac{1}{n}}} \sim \mathcal{T}(n + m - 2)
$$

##### Пример:

```{r}
# Формула за смесено извадъчно стандартно отклонение
pooled_sd <- function (x, y) {
  n1 <- length(x)
  n2 <- length(y)
  sqrt(
    ((n1 - 1) * var(x) + (n2 - 1) * var(y))
    /
    (n1 + n2 - 2)
  )
}

# броя на елементите в двете случайни извадки които ще симулираме
n <- 30
m <- 40

# Симулации с различен брой над с.в.
x <- rnorm(n, 3, 2)
y <- rnorm(m, 4, 2)

# Степени на свобода
degrees_of_freedom <- n + m - 2

# Наблюдавана стойност t на Т-статистиката
t <- (mean(x) - mean(y)) / (pooled_sd(x, y) * sqrt((1 / n) + (1 / m)))

# Изчисление за pvalue при двустранен тест
pvalue <- 2 * min(
  pt(t, degrees_of_freedom),
  pt(t, degrees_of_freedom, lower.tail = FALSE)
)

# резултат
c("t" = t, "pvalue" = pvalue, "df" = degrees_of_freedom)
```

Или с **t.test**

```{r}
t.test(x, y, var.equal = TRUE)
```

---

Когато работим с предположението, че дисперсиите на двете случайни 
величини $X$ и $Y$ не са еднакви, тоест $\sigma_X^2 := D(X) \neq D(Y) =: \sigma_Y^2$,
за степените на свобода използваме формулата за комбинирани степени на свобода.

$$
df_{c} := \frac{(\frac{S_1^2}{n} + \frac{S_2^2}{m})^2}{\frac{(S_1^2/n)^2}{n-1} + \frac{(S_2^2/m)^2}{m-1}}
$$

В този случай Т-статистиката ще е
$$
Т := \frac{\bar{X}-\bar{Y}}{\sqrt{\frac{S_1^2}{n}  + \frac{S_2^2}{n}}} \sim \mathcal{T}(df_{c})
$$

##### Пример:
```{r}
# брой наблюдения над симулираните случайни извадки
n <- 30
m <- 40

# Симулации с различен брой наблюдения над нормално разпределени с.в.
x <- rnorm(n, 3, 2)
y <- rnorm(m, 4, 3)

# Извадъчни дисперсии
v1 <- var(x)
v2 <- var(y)

# Смесени степени на свобода
degrees_of_freedom <- (
  (v1 / n + v2 / m)^2
  /
  ((v1 / n)^2 / (n - 1) + (v2 / m)^2 / (m - 1)))

t <- (mean(x) - mean(y)) / sqrt(v1 / n + v2 / m)

# Изчисление за pvalue при двустранен тест
pvalue <- 2 * min(
  pt(t, degrees_of_freedom, lower.tail = TRUE),
  pt(t, degrees_of_freedom, lower.tail = FALSE)
)

# резултат
c("t" = t, "pvalue" = pvalue, "df" = degrees_of_freedom)
```

Или за по-кратко с **t.test**

```{r}
t.test(x, y, alternative = "two.sided")
```

### Сдвоени и несдвоени данни (Paired vs Unpaired)

**Сдвоени данни (наблюдения)** от две извадки наричаме, такива при при които имаме зависимост 
между извадките и няблюденията идват 
от едни и същи индивиди, но в различен етап от време. Тоест $x_i$ и $y_i$ са наблюдения върху един и обект.  Пример за това би бил ефекта върху нивото на холестерола преди и след приемането на лекарство от едни и същи хора. При **несдвоени данни**, имаме наблюдения от 
независими извадки $X$ и $Y$. Пример за това би бил, кръвното на група която не приема определено лекарство, и кръвното на група която е приела лекарството. При **t.test** в този случай, при нулева хипотеза $H_0 := \mu_0=0$, тест статистиката $Т$ би била
$$
T := \frac{(\bar{X} - \bar{Y})-(\mu_1-\mu_2)}{st.dev(\bar{X}-\bar{Y})} = \frac{\bar{X}_D-\mu_0}{S_D/\sqrt{n}} \sim \mathcal{T}(n - 1)
$$
където $\bar{X}_D$ и $S_D$ са извадъчното средно и стандартно отклонение 
върху разликите между всички наблюдения.

##### Пример:
```{r}
# Брой елементи от които ще симулираме извадка
n <- 30

# Симулираме наблюдения от с.в.
x <- rnorm(n, 80, 4)
y <- rnorm(n, 84, 4)

# Тест статистика при сдвоен тест
t <- mean(x - y) / (sd(x - y) / sqrt(30))

# Изчисление на pvalue
pvalue <- 2 * min(pt(t, n - 1), pt(t, n - 1, lower.tail = FALSE))

# резултат
c("t" = t, "pvalue" = pvalue, "df" = n - 1)
```

Отново, можем да ползваме **t.test**

```{r}
t.test(x, y, paired = TRUE)
```
